# AWS Lambda: Concurrency and Throttling

## Concurrency Basics

The more we invoke our Lambda functions, the more **concurrent executions** we have. Lambda scales **very fast and easily**.

- At a **low scale**, you may see 2 concurrent executions.
- At a **high scale**, Lambda may scale up to **1000 concurrent executions** (default soft limit, requestable increase).

## Reserved Concurrency

To **limit** the number of concurrent executions for a Lambda function, you can set **reserved concurrency** at the function level.

> Example:  
> “This Lambda function can only have up to 50 concurrent executions.”

### Throttling Behavior

- If invocations **exceed reserved concurrency**, they are **throttled**.
- **Synchronous invocations**: return a **429 Throttle Error**.
- **Asynchronous invocations**: will **retry** and may go to **DLQ (Dead Letter Queue)** if retries fail.

> **Note**: You can request higher limits via AWS Support if you need more than 1000 concurrent executions.

## Shared Account-Level Concurrency

If you don’t set reserved concurrency, all your Lambda functions **share the account-level concurrency limit** (default: 1000).

### Example Scenario:

1. One application (e.g., via ALB) gets **massive traffic**.
2. It consumes **all available concurrency**.
3. Other applications using API Gateway, SDK, or CLI may get **throttled** as a result.

> ⚠️ Important:  
> One function exceeding concurrency limits can **starve** others in the same account.

---

## Asynchronous Invocations and Throttling

### Example: S3 Event Notifications

- Uploading multiple files to S3 triggers many Lambda executions.
- If concurrency is exhausted, new events are **throttled**.

### Retry Behavior

- Lambda places events in an **internal event queue**.
- Retries will happen for **up to 6 hours**.
- Uses **exponential backoff**: starts from 1 sec up to 5 minutes between retries.

---

## Cold Starts and Provisioned Concurrency

### What is a Cold Start?

When a **new Lambda instance** is created:
- Your **code is loaded**.
- **Initialization code** outside the handler runs.

> If your code has **heavy initialization**, the first request may have **high latency**, affecting user experience.

### Solution: Provisioned Concurrency

- Keeps a **warm pool of Lambda instances** ready to handle requests.
- **Reduces cold start latency** significantly.
- Managed via **Application Auto Scaling** (e.g., with scheduled scaling).

### Note on VPC Integration

- Historically, Lambdas in a VPC had **long cold start times**.
- As of **October–November 2019**, AWS released improvements reducing these significantly.

---

## Additional Resources

There are diagrams available that explain:
- **Reserved Concurrency**
- **Provisioned Concurrency**

> 📎 Check the slide deck for links to these diagrams.

---

## Next Steps

Let’s proceed to the **hands-on section** and explore how Lambda concurrency works in practice.
