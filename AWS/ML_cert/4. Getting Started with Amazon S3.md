## Getting Started with Amazon S3

### Introduction

**Instructor**: Okay, so let's get started with **S3**.

You may already know what S3 is, but let’s quickly review the key points you need to know to pass the **AWS Machine Learning exam**.

---

### What is Amazon S3?

- **S3** allows you to store **objects or files** in **buckets**, which will be the **centerpiece** of everything you'll do in AWS.
- Buckets must have a **globally unique name**.
- Objects (files) in S3 are identified by a **key**, which is the full file path (e.g., `bucket/my_file.txt`).
- You can use long "folder-like" key names (e.g., `my_folder1/another_folder/my_file.txt`) — note that these are not actual folders, just part of the key.
- This structure becomes important when we talk about **data partitioning** later.

---

### S3 Key Facts

- **Maximum object size**: 5 **terabytes**
  - If a dataset exceeds this, it must be split into multiple objects.
- You can add **object tags** (key-value pairs) to classify data.
  - Useful for **security**, **data lifecycle policies**, and **organization**.

---

### S3 and Machine Learning

S3 serves as the **backbone** for many AWS ML services, including:

- **Amazon SageMaker**
- **Athena**
- **Redshift Spectrum**
- **Rekognition**
- **Glue**
- **EC2**

#### Key Benefits:
- Infinite sizing – no provisioning required
- **11 nines durability** (99.999999999%)
- **Separation of storage and compute**  
  - Compute services access data in S3 without needing to reside on the same infrastructure.
- **Centralized data architecture**
- **Object storage** supports any file format:
  - Examples: `CSV`, `JSON`, `Parquet`, `ORC`, `Avro`, `Protobuf`
- Ideal for building a **data lake in the cloud**

---

## Data Partitioning in S3

### Why Partition?

Partitioning helps **speed up range queries**. For example:

- When using **Amazon Athena** (serverless query service)
- Partitioning by **date** is common:
  `s3://my-dataset/year=2022/month=10/day=21/data.csv`

### Flexible Partitioning

If you frequently query by **product**, you might instead structure:
 `s3://my-dataset/product-id=1234/year=2022/...`

> Partitioning strategy should match your most frequent query patterns.

- Some AWS tools (e.g., **Kinesis**) automatically handle partitioning for you.

---

## Hands-On: Creating an S3 Bucket

### Step-by-step

1. Go to **Amazon S3** in the AWS Console
2. Click **Create bucket**
   - Name: `aws-machine-learning-stephane-v4`
   - Choose a nearby region (e.g., Ireland)
   - Leave other settings default
3. Click **Create bucket**

---

### Adding Folders and Data

1. Inside the new bucket:
   - Create folder: `instructors`
   - Upload initial dataset (CSV file with instructor data)
2. Create a folder structure for partitioning:
   - Folder: `2022/`
     - Subfolder: `10/`
       - Subfolder: `21/`
         - Upload your dataset file (e.g., `instructor_data.csv`)

---

### Sample Dataset Structure

Uploaded CSV content:

| Instructor Name   | Course                       | Love Meter |
|-------------------|-------------------------------|-------------|
| Stephane Maarek   | AWS Machine Learning Course  | 100         |
| Frank Kane        | AWS Machine Learning Course  | 100         |

---

## Summary

In this lecture, we've:

- Introduced **Amazon S3** and its role in AWS ML workflows
- Discussed object storage, keys, and partitioning
- Set up a new S3 bucket
- Created a partitioned folder structure
- Uploaded a sample dataset

> You're now ready to move forward with using S3 as your foundational storage layer in AWS ML pipelines.

See you in the next lecture!
